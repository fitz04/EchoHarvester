# EchoHarvester 설정 파일

# 입력 소스 목록
sources:
  # E2E 테스트용 YouTube 영상
  - type: youtube_video
    url: "https://www.youtube.com/watch?v=bynU81TSbDU"
    label: "E2E테스트"

  # YouTube 채널
  # - type: youtube_channel
  #   url: "https://www.youtube.com/@channel_name"
  #   label: "채널이름"

  # YouTube 플레이리스트
  # - type: youtube_playlist
  #   url: "https://www.youtube.com/playlist?list=PL..."
  #   label: "플레이리스트이름"

  # 로컬 디렉토리 (동영상/음성 파일 일괄 처리)
  # - type: local_directory
  #   path: "/path/to/media/folder"
  #   pattern: "*.mp4"  # 파일 패턴 (*.mp4, *.wav, *.mp3 등)
  #   recursive: true   # 하위 디렉토리 포함
  #   label: "로컬영상"

  # 로컬 단일 파일
  # - type: local_file
  #   path: "/path/to/media/file.mp4"
  #   subtitle_path: "/path/to/subtitle.vtt"  # 선택사항
  #   label: "단일파일"

# 자막 설정
subtitles:
  languages: ["ko"]                    # 대상 언어
  include_auto_generated: true         # 자동생성 자막 포함 여부
  prefer_manual: true                  # 수동자막 우선

# 필터링 임계값
filters:
  min_duration_sec: 0.5                # 최소 세그먼트 길이 (초)
  max_duration_sec: 30.0               # 최대 세그먼트 길이 (초)
  min_snr_db: 10.0                     # 최소 SNR (dB)
  min_speech_ratio: 0.5                # 최소 음성 비율 (VAD 기준)
  cer_threshold_manual: 0.15           # 수동자막 CER 임계값
  cer_threshold_auto: 0.10             # 자동자막 CER 임계값 (더 엄격)

# 다운로드 설정 (YouTube 전용)
download:
  max_concurrent: 3                    # 동시 다운로드 수
  rate_limit: "1M"                     # 다운로드 속도 제한
  retry_count: 3                       # 재시도 횟수
  retry_delay_sec: 5                   # 재시도 대기 시간 (초)

# 오디오 설정
audio:
  sample_rate: 16000                   # 샘플링 레이트 (Hz)
  format: "wav"                        # 출력 포맷
  channels: 1                          # 모노
  segment_padding_sec: 0.0             # 세그먼트 앞뒤 패딩 (초) - FA 사용 시 0.0 권장

# Forced Alignment 설정
forced_alignment:
  enabled: true                          # forced alignment 활성화
  model: "Qwen/Qwen3-ForcedAligner-0.6B" # FA 모델
  device: "auto"                         # auto, cuda, mps, cpu
  compute_type: "auto"                   # auto, bfloat16, float16, float32
  language: "ko"                         # 대상 언어

# ASR 검증 설정
validation:
  backend: "qwen-asr"                  # qwen-asr 또는 faster-whisper
  model: "Qwen/Qwen3-ASR-1.7B"        # ASR 모델 (Qwen3-ASR-1.7B / Systran/faster-whisper-medium 등)
  device: "auto"                       # auto, cuda, mps, cpu (auto: CUDA→MPS→CPU 순 폴백)
  compute_type: "auto"                 # auto, bfloat16, float16, int8, float32
  batch_size: 16                       # 배치 크기
  beam_size: 5                         # 빔 서치 크기 (faster-whisper용)
  language: "ko"                       # 강제 언어 설정

# 경로 설정
paths:
  work_dir: "./work"                   # 작업 중간 파일 경로
  output_dir: "./output"               # Lhotse Shar 출력 경로
  archive_dir: "./archive"             # 원본 보관 경로 (선택)
  db_path: "./echoharvester.db"        # SQLite 데이터베이스 경로

# 파이프라인 설정
pipeline:
  num_cpu_workers: 4                   # CPU 전처리 워커 수
  gpu_queue_size: 100                  # GPU 큐 버퍼 크기
  checkpoint_interval: 50              # N개 처리마다 체크포인트
  auto_resume: true                    # 자동 재개 활성화

# 웹 서버 설정
web:
  host: "127.0.0.1"                    # 바인딩 호스트
  port: 8000                           # 포트
  debug: false                         # 디버그 모드
  reload: false                        # 자동 리로드

# 로깅 설정
logging:
  level: "INFO"                        # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/echoharvester.log"     # 로그 파일 경로 (null이면 콘솔만)

# 훈련 설정 (Conformer CTC)
training:
  shar_sources:                        # Shar 데이터 소스 경로 목록
    # - "./output/shar"                 # 기존 소량 데이터 (1 YouTube, 120 cuts)
    - "/mnt/z/data/shar_data/temp"      # ~79MB, 5 shards
    - "/mnt/z/data/shar_data/radio"     # ~159MB, 9 shards
    - "/mnt/z/data/shar_data/medical"   # ~174MB, 4 shards
  data_dir: "./training_data"          # 분할된 학습 데이터 경로
  exp_dir: "./exp"                     # 실험 결과 (체크포인트, 로그)
  split:
    train_ratio: 0.9                   # 훈련 세트 비율
    val_ratio: 0.05                    # 검증 세트 비율
    test_ratio: 0.05                   # 테스트 세트 비율
    seed: 42                           # 재현성 시드
  tokenizer:
    type: "char"                       # character-level (한글 음절)
  features:
    num_mel_bins: 80                   # Mel 필터뱅크 차원
  model:
    type: "conformer_ctc"              # 모델 타입: conformer_ctc 또는 zipformer_ctc
    attention_dim: 256                 # 어텐션 차원
    num_encoder_layers: 12             # 인코더 레이어 수
    num_attention_heads: 4             # 어텐션 헤드 수
    feedforward_dim: 2048              # FFN 차원
    depthwise_conv_kernel_size: 31     # ConvModule 커널 크기
    dropout: 0.1                       # 드롭아웃
  # Zipformer2 모델 사용 시 아래 설정으로 교체:
  # model:
  #   type: "zipformer_ctc"
  #   encoder_dim: "192,256,384,512,384,256"        # 스택별 인코더 차원
  #   num_encoder_layers: "2,2,3,4,3,2"             # 스택별 레이어 수
  #   num_heads: "4,4,4,8,4,4"                      # 스택별 어텐션 헤드 수
  #   feedforward_dim: "512,768,1024,1536,1024,768"  # 스택별 FFN 차원
  #   cnn_module_kernel: "31,31,15,15,15,31"         # 스택별 Conv 커널
  #   downsampling_factor: "1,2,4,8,4,2"             # 스택별 다운샘플링
  #   dropout: 0.1
  training_params:
    num_epochs: 50                     # 전체 에포크 수
    max_duration: 200.0                # 배치당 최대 오디오 길이 (초)
    lr_factor: 2.5                     # Noam LR factor
    warm_step: 5000                    # 워밍업 스텝
    weight_decay: 0.000001             # 가중치 감쇠
    clip_grad_norm: 5.0                # 그래디언트 클리핑
    log_interval: 50                   # 로그 출력 간격 (배치)
    valid_interval: 1                  # 검증 간격 (에포크)
    keep_last_n: 5                     # 최근 N개 체크포인트 유지
  device: "auto"                       # auto, cpu, cuda, mps
